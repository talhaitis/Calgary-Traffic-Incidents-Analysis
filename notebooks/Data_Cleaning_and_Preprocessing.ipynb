{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731d40f8-5c0e-44dc-a811-5cdfb5d23090",
   "metadata": {},
   "source": [
    "# Section 1: Import Libraries and Load Data\n",
    "This section imports necessary Python libraries and loads the traffic incidents dataset into a DataFrame for initial inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58edb6c0-3172-41b7-aa96-1994bcc86daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51756 entries, 0 to 51755\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   INCIDENT INFO  51756 non-null  object \n",
      " 1   DESCRIPTION    51754 non-null  object \n",
      " 2   START_DT       51756 non-null  object \n",
      " 3   MODIFIED_DT    37699 non-null  object \n",
      " 4   QUADRANT       37697 non-null  object \n",
      " 5   Longitude      51756 non-null  float64\n",
      " 6   Latitude       51756 non-null  float64\n",
      " 7   Count          51756 non-null  int64  \n",
      " 8   id             51756 non-null  object \n",
      " 9   Point          51756 non-null  object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 3.9+ MB\n",
      "\n",
      "First 5 Rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT INFO</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>START_DT</th>\n",
       "      <th>MODIFIED_DT</th>\n",
       "      <th>QUADRANT</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Count</th>\n",
       "      <th>id</th>\n",
       "      <th>Point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Westbound 16 Avenue at Deerfoot Trail NE</td>\n",
       "      <td>Stalled vehicle.  Partially blocking the right...</td>\n",
       "      <td>2022-06-21 7:31</td>\n",
       "      <td>2022-06-21 7:33</td>\n",
       "      <td>NE</td>\n",
       "      <td>-114.026687</td>\n",
       "      <td>51.067485</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-21T07:31:4051.067485129276236-114.0266...</td>\n",
       "      <td>POINT (-114.02668672232672 51.067485129276236)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 Avenue and 4 Street SW</td>\n",
       "      <td>Traffic incident. Blocking multiple lanes</td>\n",
       "      <td>2022-06-21 4:02</td>\n",
       "      <td>2022-06-21 4:12</td>\n",
       "      <td>SW</td>\n",
       "      <td>-114.071481</td>\n",
       "      <td>51.042624</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-21T04:02:1151.04262449261462-114.07148...</td>\n",
       "      <td>POINT (-114.07148057660925 51.04262449261462)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68 Street and Memorial Drive E</td>\n",
       "      <td>Traffic incident.</td>\n",
       "      <td>2022-06-20 23:53</td>\n",
       "      <td>2022-06-20 23:55</td>\n",
       "      <td>NE</td>\n",
       "      <td>-113.935553</td>\n",
       "      <td>51.052474</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-20T23:53:0851.0524735056658-113.935553...</td>\n",
       "      <td>POINT (-113.935553325751 51.0524735056658)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eastbound 16 Avenue and 36 Street NE</td>\n",
       "      <td>Traffic incident. Blocking the left shoulder</td>\n",
       "      <td>2022-06-20 16:43</td>\n",
       "      <td>2022-06-20 17:17</td>\n",
       "      <td>NE</td>\n",
       "      <td>-113.989219</td>\n",
       "      <td>51.067086</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-20T16:43:2151.06708565896752-113.98921...</td>\n",
       "      <td>POINT (-113.98921905311566 51.06708565896752)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barlow Trail and 61 Avenue SE</td>\n",
       "      <td>Traffic incident.</td>\n",
       "      <td>2022-06-20 16:42</td>\n",
       "      <td>2022-06-20 17:28</td>\n",
       "      <td>SE</td>\n",
       "      <td>-113.985727</td>\n",
       "      <td>50.998727</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-20T16:42:1250.99872748477766-113.98572...</td>\n",
       "      <td>POINT (-113.98572655353505 50.99872748477766)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                INCIDENT INFO  \\\n",
       "0   Westbound 16 Avenue at Deerfoot Trail NE    \n",
       "1                  11 Avenue and 4 Street SW    \n",
       "2             68 Street and Memorial Drive E    \n",
       "3       Eastbound 16 Avenue and 36 Street NE    \n",
       "4              Barlow Trail and 61 Avenue SE    \n",
       "\n",
       "                                         DESCRIPTION          START_DT  \\\n",
       "0  Stalled vehicle.  Partially blocking the right...   2022-06-21 7:31   \n",
       "1          Traffic incident. Blocking multiple lanes   2022-06-21 4:02   \n",
       "2                                  Traffic incident.  2022-06-20 23:53   \n",
       "3       Traffic incident. Blocking the left shoulder  2022-06-20 16:43   \n",
       "4                                  Traffic incident.  2022-06-20 16:42   \n",
       "\n",
       "        MODIFIED_DT QUADRANT   Longitude   Latitude  Count  \\\n",
       "0   2022-06-21 7:33       NE -114.026687  51.067485      1   \n",
       "1   2022-06-21 4:12       SW -114.071481  51.042624      1   \n",
       "2  2022-06-20 23:55       NE -113.935553  51.052474      1   \n",
       "3  2022-06-20 17:17       NE -113.989219  51.067086      1   \n",
       "4  2022-06-20 17:28       SE -113.985727  50.998727      1   \n",
       "\n",
       "                                                  id  \\\n",
       "0  2022-06-21T07:31:4051.067485129276236-114.0266...   \n",
       "1  2022-06-21T04:02:1151.04262449261462-114.07148...   \n",
       "2  2022-06-20T23:53:0851.0524735056658-113.935553...   \n",
       "3  2022-06-20T16:43:2151.06708565896752-113.98921...   \n",
       "4  2022-06-20T16:42:1250.99872748477766-113.98572...   \n",
       "\n",
       "                                            Point  \n",
       "0  POINT (-114.02668672232672 51.067485129276236)  \n",
       "1   POINT (-114.07148057660925 51.04262449261462)  \n",
       "2      POINT (-113.935553325751 51.0524735056658)  \n",
       "3   POINT (-113.98921905311566 51.06708565896752)  \n",
       "4   POINT (-113.98572655353505 50.99872748477766)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/Traffic_Incidents_20241225.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display dataset information\n",
    "print(\"Dataset Info:\")\n",
    "data.info()\n",
    "\n",
    "# Display first 5 rows\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30e2c3-4654-484b-94cd-82556402a5a9",
   "metadata": {},
   "source": [
    "# Section 2: Check Missing Values\n",
    "This section examines missing values in the dataset and plans how to handle them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02950e9-0bca-4b76-8157-63ed90c87631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " INCIDENT INFO        0\n",
      "DESCRIPTION          2\n",
      "START_DT             0\n",
      "MODIFIED_DT      14057\n",
      "QUADRANT         14059\n",
      "Longitude            0\n",
      "Latitude             0\n",
      "Count                0\n",
      "id                   0\n",
      "Point                0\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values:\n",
      " INCIDENT INFO     0.000000\n",
      "DESCRIPTION       0.003864\n",
      "START_DT          0.000000\n",
      "MODIFIED_DT      27.160136\n",
      "QUADRANT         27.164000\n",
      "Longitude         0.000000\n",
      "Latitude          0.000000\n",
      "Count             0.000000\n",
      "id                0.000000\n",
      "Point             0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Percentage of missing values\n",
    "missing_percent = (missing_values / len(data)) * 100\n",
    "print(\"\\nPercentage of Missing Values:\\n\", missing_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b50df-fb27-4437-b3fd-e57ca247033c",
   "metadata": {},
   "source": [
    "# Section 3: Handle Missing Values\n",
    "In this section, we address missing values based on their nature:\n",
    "1. 'DESCRIPTION' has 2 missing values, so we fill them with 'Unknown'.\n",
    "2. 'MODIFIED_DT' has 27.16% missing values, which can be filled with 'START_DT' since it's the closest timestamp available.\n",
    "3. 'QUADRANT' has 27.16% missing values, which can be filled with 'Unknown' as a placeholder for undefined locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd3b594-ce61-4874-b083-b8dc95bf78d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Handling:\n",
      " INCIDENT INFO    0\n",
      "DESCRIPTION      0\n",
      "START_DT         0\n",
      "MODIFIED_DT      0\n",
      "QUADRANT         0\n",
      "Longitude        0\n",
      "Latitude         0\n",
      "Count            0\n",
      "id               0\n",
      "Point            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].fillna('Unknown')  # Replace missing descriptions\n",
    "data['MODIFIED_DT']= data['MODIFIED_DT'].fillna(data['START_DT'])  # Replace missing modified date with start date\n",
    "data['QUADRANT'] = data['QUADRANT'].fillna('Unknown')  # Replace missing quadrant with 'Unknown'\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(\"Missing Values After Handling:\\n\", data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f8ce0b-5456-4e59-bf7e-3853fbe3db9f",
   "metadata": {},
   "source": [
    "# Section 4: Convert Date Columns and Extract Features\n",
    "The date columns are converted into datetime objects to enable time-based analysis.  \n",
    "New features like `Start_Date`, `Start_Hour`, and `Start_Weekday` are added to analyze temporal patterns of traffic incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c248ff6d-9f71-4bd9-ba65-ad6a530b493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             START_DT         MODIFIED_DT  Start_Date  Start_Hour  \\\n",
      "0 2022-06-21 07:31:00 2022-06-21 07:33:00  2022-06-21           7   \n",
      "1 2022-06-21 04:02:00 2022-06-21 04:12:00  2022-06-21           4   \n",
      "2 2022-06-20 23:53:00 2022-06-20 23:55:00  2022-06-20          23   \n",
      "3 2022-06-20 16:43:00 2022-06-20 17:17:00  2022-06-20          16   \n",
      "4 2022-06-20 16:42:00 2022-06-20 17:28:00  2022-06-20          16   \n",
      "\n",
      "   Start_Weekday  \n",
      "0              1  \n",
      "1              1  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime format\n",
    "data['START_DT'] = pd.to_datetime(data['START_DT'])\n",
    "data['MODIFIED_DT'] = pd.to_datetime(data['MODIFIED_DT'])\n",
    "\n",
    "# Extract additional time-based features\n",
    "data['Start_Date'] = data['START_DT'].dt.date\n",
    "data['Start_Hour'] = data['START_DT'].dt.hour\n",
    "data['Start_Weekday'] = data['START_DT'].dt.weekday  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Display modified data\n",
    "print(data[['START_DT', 'MODIFIED_DT', 'Start_Date', 'Start_Hour', 'Start_Weekday']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e7865-c8e8-43e4-a5ca-75751790b3c1",
   "metadata": {},
   "source": [
    "# Section 5: Advanced Data Cleaning\n",
    "This section performs additional checks and cleaning to ensure data quality and consistency:\n",
    "1. Check for duplicate rows and drop them if necessary.\n",
    "2. Validate geographic coordinates (latitude and longitude) to ensure all values are valid.\n",
    "3. Standardize text data, such as descriptions, to avoid inconsistencies.\n",
    "4. Verify logical consistency in time fields (e.g., modified date >= start date).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d8293d-93d1-4468-8990-6080795823db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = data.duplicated()\n",
    "print(\"Number of Duplicate Rows:\", duplicates.sum())\n",
    "\n",
    "# # Drop duplicates if any\n",
    "# data = data.drop_duplicates()\n",
    "# print(\"Duplicates removed. Remaining rows:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0855b06-eb20-44d7-941d-472b99b736f1",
   "metadata": {},
   "source": [
    "# Section 6: Validate Coordinates\n",
    "We verify whether latitude and longitude values are within valid ranges:\n",
    "- Latitude: -90 to 90\n",
    "- Longitude: -180 to 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2cdda7-1def-4db4-b924-2b18039f83a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid latitude values: 0\n",
      "Invalid longitude values: 0\n"
     ]
    }
   ],
   "source": [
    "# Check valid latitude and longitude ranges\n",
    "invalid_lat = data[(data['Latitude'] < -90) | (data['Latitude'] > 90)]\n",
    "invalid_lon = data[(data['Longitude'] < -180) | (data['Longitude'] > 180)]\n",
    "\n",
    "print(f\"Invalid latitude values: {len(invalid_lat)}\")\n",
    "print(f\"Invalid longitude values: {len(invalid_lon)}\")\n",
    "\n",
    "# Drop rows with invalid coordinates if any\n",
    "data = data[(data['Latitude'] >= -90) & (data['Latitude'] <= 90)]\n",
    "data = data[(data['Longitude'] >= -180) & (data['Longitude'] <= 180)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75aea4-20e4-4fa7-aa4a-f302e93a35d1",
   "metadata": {},
   "source": [
    "# Section 7: Detect Outliers in Time Features\n",
    "We inspect the start and modified timestamps for any anomalies, such as future or very old dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03739c11-3034-4a43-b496-a4f14808afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest Start Date: 2016-12-06 10:00:00\n",
      "Latest Start Date: 2024-12-25 21:54:00\n",
      "Earliest Modified Date: 2016-12-06 10:01:00\n",
      "Latest Modified Date: 2024-12-25 21:55:00\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in datetime columns\n",
    "print(f\"Earliest Start Date: {data['START_DT'].min()}\")\n",
    "print(f\"Latest Start Date: {data['START_DT'].max()}\")\n",
    "\n",
    "print(f\"Earliest Modified Date: {data['MODIFIED_DT'].min()}\")\n",
    "print(f\"Latest Modified Date: {data['MODIFIED_DT'].max()}\")\n",
    "\n",
    "# Filter out unreasonable dates if needed\n",
    "# Example: Only keep incidents from the last 10 years\n",
    "import datetime\n",
    "start_limit = datetime.datetime.now() - pd.DateOffset(years=10)\n",
    "data = data[data['START_DT'] >= start_limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6859b0-f3ae-4105-8880-f3456864a79c",
   "metadata": {},
   "source": [
    "# Section 8: Standardize Text Columns\n",
    "We clean and standardize text columns such as 'DESCRIPTION' and 'QUADRANT' to ensure consistency and remove extra whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec66776-cc37-4020-a627-fd83312d9621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         DESCRIPTION QUADRANT\n",
      "0  stalled vehicle.  partially blocking the right...       NE\n",
      "1          traffic incident. blocking multiple lanes       SW\n",
      "2                                  traffic incident.       NE\n",
      "3       traffic incident. blocking the left shoulder       NE\n",
      "4                                  traffic incident.       SE\n"
     ]
    }
   ],
   "source": [
    "# Standardize 'DESCRIPTION' and 'QUADRANT'\n",
    "data['DESCRIPTION'] = data['DESCRIPTION'].str.strip().str.lower()\n",
    "data['QUADRANT'] = data['QUADRANT'].str.strip().str.upper()\n",
    "\n",
    "# Verify changes\n",
    "print(data[['DESCRIPTION', 'QUADRANT']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec352cc-83c8-42bd-9613-ad9473494314",
   "metadata": {},
   "source": [
    "# Section 9: Save Cleaned Data\n",
    "The cleaned dataset is saved as a CSV file to preserve progress and make it easier to load in future analysis steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e54ea9aa-c8e1-4490-9ddf-6695579b20c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "data.to_csv('../data/Cleaned_Traffic_Incidents.csv', index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
